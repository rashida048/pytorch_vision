{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D5SEvLvO60K",
        "outputId": "37aa0fcc-4771-4c7d-cfb8-7e6be7764580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-11 04:19:05--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/intro-to-pytorch/intro-to-pytorch.zip\n",
            "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.218.234.73, 52.218.220.97, 52.92.228.58, ...\n",
            "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.218.234.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2372 (2.3K) [application/zip]\n",
            "Saving to: ‘intro-to-pytorch.zip’\n",
            "\n",
            "\rintro-to-pytorch.zi   0%[                    ]       0  --.-KB/s               \rintro-to-pytorch.zi 100%[===================>]   2.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-11 04:19:06 (105 MB/s) - ‘intro-to-pytorch.zip’ saved [2372/2372]\n",
            "\n",
            "/content/intro-to-pytorch\n"
          ]
        }
      ],
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/intro-to-pytorch/intro-to-pytorch.zip\n",
        "!unzip -qq intro-to-pytorch.zip\n",
        "%cd intro-to-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from torch.optim import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_blobs\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "dOSRIjEB9b2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_model(inFeatures=4, hiddenDim=8, nbClasses = 3):\n",
        "  mlpModel = nn.Sequential(OrderedDict([\n",
        "      (\"hidden_layer_1\", nn.Linear(inFeatures, hiddenDim)),\n",
        "      (\"activation_1\", nn.ReLU()),\n",
        "      (\"Output_layer\", nn.Linear(hiddenDim, nbClasses))\n",
        "  ]))\n",
        "  return mlpModel"
      ],
      "metadata": {
        "id": "tkITTR-F9xqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_batch(inputs, targets, batchSize):\n",
        "  for i in range(0, inputs.shape[0], batchSize):\n",
        "    yield (inputs[i:i + batchSize], targets[i:i+batchSize])"
      ],
      "metadata": {
        "id": "JjITM51b-WlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-2\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEAXh9zB-v8Q",
        "outputId": "d7f928ba-78b3-426a-ecf6-874c23afec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training using cpu...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] preparing data...\")\n",
        "(X, y) = make_blobs(n_samples=1000, n_features=4, centers=3, cluster_std=2.5, random_state=95)\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.15, random_state=95)\n",
        "\n",
        "trainX = torch.from_numpy(trainX).float()\n",
        "testX = torch.from_numpy(testX).float()\n",
        "trainY = torch.from_numpy(trainY).float()\n",
        "testY = torch.from_numpy(testY).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUu51UUm_cae",
        "outputId": "497f3afc-78fc-4eb9-bf5a-b5f5ea300add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] preparing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = get_training_model().to(DEVICE)\n",
        "print(mlp)\n",
        "\n",
        "opt = SGD(mlp.parameters(), lr=LR)\n",
        "lossFunc = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwMh9e_AcHJ1",
        "outputId": "84691755-d873-40b1-f256-59eb1b2bcc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (hidden_layer_1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (Output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(0, EPOCHS):\n",
        "  print(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
        "\n",
        "  trainLoss = 0\n",
        "  trainACC = 0\n",
        "  samples = 0\n",
        "  mlp.train()\n",
        "\n",
        "  for (batchX, batchY) in next_batch(trainX, trainY, BATCH_SIZE):\n",
        "    (batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\n",
        "    predictions = mlp(batchX)\n",
        "    loss = lossFunc(predictions, batchY.long())\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    trainLoss += loss.item() * batchY.size(0)\n",
        "    trainACC += (predictions.max(1)[1] == batchY).sum().item()\n",
        "    samples += batchY.size(0)\n",
        "\n",
        "    trainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "\n",
        "    print(trainTemplate.format(epoch + 1, (trainLoss / samples),\n",
        "                               (trainACC / samples)))\n",
        "\n",
        "    testLoss = 0\n",
        "    testACC = 0\n",
        "    samples = 0\n",
        "    mlp.eval()\n",
        "\n",
        "    with torch.no_grad():\n"
      ],
      "metadata": {
        "id": "r5RrZGuxc2Ef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}